import os
import sys
import time
import subprocess
import random
from datetime import datetime
from dateutil.relativedelta import relativedelta

# [Step 0] ìŠ¤ë§ˆíŠ¸ ëŸ°ì²˜ (Smart Launcher) - ë¬´í•œ ì„¤ì¹˜ ë²„ê·¸ ìˆ˜ì •
# --------------------------------------------------------------------------------
def install_and_launch():
    # íŒ¨í‚¤ì§€ëª…(pip install ì´ë¦„) : ëª¨ë“ˆëª…(import ì´ë¦„) ë§¤í•‘
    required = {
        "streamlit": "streamlit",
        "plotly": "plotly",
        "google-generativeai": "google.generativeai",
        "python-dotenv": "dotenv",
        "python-dateutil": "dateutil"
    }
    
    needs_install = []
    print("ğŸ› ï¸ [ì‹œìŠ¤í…œ] í•„ìˆ˜ ì—”ì§„ ì ê²€ ì¤‘...", end="")
    
    for package, module in required.items():
        try:
            __import__(module)
        except ImportError:
            needs_install.append(package)
    
    if needs_install:
        print(f"\nâš ï¸ í•„ìˆ˜ ë„êµ¬ ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤: {', '.join(needs_install)}")
        print("â³ ì„¤ì¹˜ ì¤‘... (ì•½ 30ì´ˆ ì†Œìš”)")
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install"] + needs_install)
            print("âœ… ì„¤ì¹˜ ì™„ë£Œ! ëŒ€ì‹œë³´ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            # ì„¤ì¹˜ ì§í›„ ì¬ì‹¤í–‰ (Windows í™˜ê²½ í˜¸í™˜ì„± í™•ë³´)
            os.execv(sys.executable, [sys.executable, "-m", "streamlit", "run", __file__])
        except Exception as e:
            print(f"âŒ ì„¤ì¹˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            sys.exit(1)
    else:
        print(" ì™„ë£Œ! (ëª¨ë“  ì—”ì§„ ì •ìƒ)")

# Streamlit êµ¬ë™ ë¡œì§ (ì¬ê·€ í˜¸ì¶œ ë°©ì§€)
if "streamlit" not in sys.modules:
    install_and_launch()
    # ì„¤ì¹˜ê°€ ë‹¤ ë˜ì–´ìˆë‹¤ë©´ Streamlitìœ¼ë¡œ ì‹¤í–‰ ì „í™˜
    from streamlit.web import cli as stcli
    sys.argv = ["streamlit", "run", __file__]
    sys.exit(stcli.main())

# ================================================================================
# [ì—¬ê¸°ì„œë¶€í„° ëŒ€ì‹œë³´ë“œ ì½”ë“œ]
# ================================================================================
import streamlit as st
import plotly.express as px
import pandas as pd
import google.generativeai as genai
from dotenv import load_dotenv

load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
if api_key: genai.configure(api_key=api_key)

# --------------------------------------------------------------------------------
# [UI ë””ìì¸] 0.1% Pro Styling
# --------------------------------------------------------------------------------
st.set_page_config(page_title="ì§€ìƒ AI Pro | ë¶€ë™ì‚° ë”¥í…Œí¬", page_icon="ğŸ¢", layout="wide")

st.markdown("""
    <style>
    /* ë“±ê¸‰ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .grade-box {
        padding: 20px; border-radius: 12px; text-align: center; color: white;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1); margin-bottom: 10px;
    }
    .grade-s { background: linear-gradient(135deg, #00b09b, #96c93d); } /* Green */
    .grade-a { background: linear-gradient(135deg, #4facfe, #00f2fe); } /* Blue */
    .grade-b { background: linear-gradient(135deg, #f093fb, #f5576c); } /* Red/Pink */
    .grade-title { font-size: 48px; font-weight: 800; margin: 0; }
    .grade-desc { font-size: 16px; opacity: 0.9; }
    
    /* ë©”íŠ¸ë¦­ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    div[data-testid="metric-container"] {
        background-color: #f8f9fa; border: 1px solid #dee2e6;
        padding: 15px; border-radius: 10px;
    }
    </style>
""", unsafe_allow_html=True)

# --------------------------------------------------------------------------------
# [Backend Logic] Opal + FactChecker + Brain
# --------------------------------------------------------------------------------
def get_best_model():
    """ëª¨ë¸ ìë™ íƒìƒ‰ (ì—ëŸ¬ ë°©ì§€)"""
    try:
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        # 2.0 Flashê°€ ìˆìœ¼ë©´ ìµœìš°ì„  ì‚¬ìš© (ì†ë„/ì„±ëŠ¥ ìµœê°•)
        preferred = ['models/gemini-2.0-flash', 'models/gemini-1.5-flash', 'models/gemini-pro']
        for p in preferred:
            if p in models: return p
        return 'gemini-pro'
    except: return 'gemini-pro'

class FactChecker:
    @staticmethod
    def process(data):
        target_bonds = []
        saved_interest = 0
        
        # ë‚ ì§œ ë° ê¸ˆë¦¬ ì‹œë®¬ë ˆì´ì…˜
        for bond in data['bonds']:
            target_date = datetime.strptime(bond['date'], "%Y.%m.%d")
            diff = relativedelta(datetime.now(), target_date)
            months = diff.years * 12 + diff.months
            
            # 24ê°œì›” ì´ìƒì´ê±°ë‚˜ ëŒ€ë¶€ì—…ì´ë©´ íƒ€ê²Ÿ
            is_target = months >= 24 or bond['type'] == "ëŒ€ë¶€ì—…"
            if is_target:
                target_bonds.append(bond)
                # ì ˆê°ì•¡ ì¶”ì •: ëŒ€ë¶€ì—…(10%p), 1ê¸ˆìœµ(1.5%p)
                gap = 0.10 if bond['type'] == "ëŒ€ë¶€ì—…" else 0.015
                saved_interest += bond['amount'] * gap
        
        total_bond = sum(b['amount'] for b in data['bonds'])
        ltv = round((total_bond / data['market_price']) * 100, 2)
        
        return {
            "ltv": ltv,
            "refinance_count": len(target_bonds),
            "total_bond": total_bond,
            "saved_interest_year": int(saved_interest),
            "risk_score": 100 - (len(data['restrictions']) * 15) - (20 if ltv > 80 else 0)
        }

def run_simulation(address):
    # Opal Agent UI Simulation
    with st.status("ğŸ’ Opal Agent ê°€ë™ ì¤‘...", expanded=True) as status:
        st.write("ğŸŒ ì¸í„°ë„·ë“±ê¸°ì†Œ(IROS) ì ‘ì† ë° ë³´ì•ˆ ëª¨ë“ˆ ë¡œë“œ...")
        time.sleep(0.4)
        st.write("ğŸ“„ ë“±ê¸°ì‚¬í•­ì „ë¶€ì¦ëª…ì„œ(ë§ì†Œì‚¬í•­í¬í•¨) ë°œê¸‰ ì™„ë£Œ")
        time.sleep(0.4)
        st.write("ğŸ—ï¸ ê±´ì¶•ë¬¼ëŒ€ì¥ ë° í† ì§€ì´ìš©ê³„íšì› ëŒ€ì¡° ì¤‘...")
        time.sleep(0.4)
        status.update(label="âœ… ë°ì´í„° ìˆ˜ì§‘ ë° ë¬´ê²°ì„± ê²€ì¦ ì™„ë£Œ!", state="complete", expanded=False)

    # ê°€ìƒ ë°ì´í„° (ì¼€ì´ìŠ¤: í†µì§„ì ë„ì‚¬ë¦¬ ê³µì¥)
    raw_data = {
        "address": address,
        "market_price": 850000000, 
        "bonds": [
            {"bank": "êµ­ë¯¼ì€í–‰", "date": "2018.06.20", "amount": 400000000, "type": "1ê¸ˆìœµ"},
            {"bank": "ëŸ¬ì‹œì•¤ìºì‹œ", "date": "2024.01.10", "amount": 200000000, "type": "ëŒ€ë¶€ì—…"}
        ],
        "restrictions": ["ì‹ íƒë“±ê¸°(ìš°ë¦¬ìì‚°ì‹ íƒ)", "ì••ë¥˜(ê¹€í¬ì„¸ë¬´ì„œ)"]
    }
    
    facts = FactChecker.process(raw_data)
    
    # Brain (Gemini)
    model_name = get_best_model()
    model = genai.GenerativeModel(model_name)
    prompt = f"""
    ë¶€ë™ì‚° ê¶Œë¦¬ë¶„ì„ ë° ê¸ˆìœµ ì»¨ì„¤íŒ… ë¦¬í¬íŠ¸ ì‘ì„±.
    - ì…ë ¥: {raw_data}
    - íŒ©íŠ¸: {facts}
    
    [ì‘ì„± ì›ì¹™]
    1. ë“±ê¸‰: B- (ë¦¬ìŠ¤í¬ëŠ” ìˆìœ¼ë‚˜ ê¸ˆìœµ í•´ê²°ì±… ëª…í™•í•¨)
    2. í•µì‹¬ ì „ëµ: ëŒ€ë¶€ì—…(2ì–µ) ë° ì‹ íƒ ë§ì†Œ ë™ì‹œ ì§„í–‰ ì‹œ ê°€ì¹˜ ìƒìŠ¹ë¶„ ì„¤ëª….
    3. í†¤ì•¤ë§¤ë„ˆ: ëƒ‰ì² í•˜ê³  ì „ë¬¸ì ì¸ ê¸ˆìœµ ì „ë¬¸ê°€ ì–´ì¡°.
    """
    try:
        response = model.generate_content(prompt)
        ai_report = response.text
    except:
        ai_report = "âš ï¸ AI ì„œë²„ ì—°ê²° ì§€ì—°. íŒ©íŠ¸ ë°ì´í„° ìœ„ì£¼ë¡œ ì°¸ê³ í•˜ì‹­ì‹œì˜¤."

    return raw_data, facts, ai_report

# --------------------------------------------------------------------------------
# [Frontend] ë©”ì¸ ëŒ€ì‹œë³´ë“œ
# --------------------------------------------------------------------------------
# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2040/2040504.png", width=50)
    st.markdown("### **Jisang AI Pro**")
    st.caption("Ver 3.5.2 (Build 20260118)")
    st.markdown("---")
    st.success(f"ğŸŸ¢ System Online\n\nModel: {get_best_model()}")
    st.markdown("---")
    st.info("**Developer Mode**\n\nAll Modules Active")

# ë©”ì¸ í™”ë©´
st.title("ğŸ™ï¸ ì§€ìƒ AI | ë¶€ë™ì‚° ë”¥í…Œí¬ ì†”ë£¨ì…˜")
st.markdown("##### :zap: ë°ì´í„° ë¬´ê²°ì„±(Integrity) ê¸°ë°˜ ì´ˆê²©ì°¨ ì˜ì‚¬ê²°ì • ì‹œìŠ¤í…œ")
st.markdown("---")

# ì…ë ¥ì°½
c1, c2 = st.columns([3, 1])
with c1:
    addr_input = st.text_input("ì£¼ì†Œ ì…ë ¥", "ê¹€í¬ì‹œ í†µì§„ì ë„ì‚¬ë¦¬ 163-1", label_visibility="collapsed")
with c2:
    start_btn = st.button("ğŸš€ ì›í´ë¦­ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True)

if start_btn:
    if not api_key:
        st.error("âŒ API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    else:
        raw, facts, ai_text = run_simulation(addr_input)

        # 1. ë“±ê¸‰ ë° í•µì‹¬ ì§€í‘œ
        st.markdown("### ğŸ¯ ë¶„ì„ ê²°ë¡ ")
        col_grade, col_metrics = st.columns([1, 2])
        
        with col_grade:
            # ë“±ê¸‰ ë¡œì§
            score = facts['risk_score']
            if score >= 80: g_cls, g_txt = "grade-s", "S (ê°•ë ¥ ì¶”ì²œ)"
            elif score >= 60: g_cls, g_txt = "grade-a", "A (ì•ˆì „)"
            elif score >= 40: g_cls, g_txt = "grade-b", "B- (ì£¼ì˜/ê¸°íšŒ)"
            else: g_cls, g_txt = "grade-c", "C (ìœ„í—˜)"
            
            st.markdown(f"""
                <div class="grade-box {g_cls}">
                    <p class="grade-title">{g_txt.split()[0]}</p>
                    <p class="grade-desc">{g_txt}</p>
                </div>
            """, unsafe_allow_html=True)

        with col_metrics:
            m1, m2, m3 = st.columns(3)
            m1.metric("LTV (ë‹´ë³´ë¹„ìœ¨)", f"{facts['ltv']}%", "ì•ˆì •ê¶Œ ëŒ€ë¹„ +20%", delta_color="inverse")
            m2.metric("ê¶Œë¦¬ ë¦¬ìŠ¤í¬", f"{len(raw['restrictions'])}ê±´", "ì‹ íƒ/ì••ë¥˜", delta_color="inverse")
            m3.metric("ğŸ’° ëŒ€í™˜ ê¸°ëŒ€ìˆ˜ìµ", f"ì—° {facts['saved_interest_year']/10000:,.0f}ë§Œ ì›", "ì¦‰ì‹œ ì ˆê°", delta_color="normal")

        # 2. ê¸ˆìœµ ì°¨íŠ¸ (ì‹œê°í™”)
        st.markdown("---")
        st.markdown("### ğŸ“Š ê¸ˆìœµ ë¹„ìš© ìµœì í™” ì‹œë®¬ë ˆì´ì…˜")
        
        chart_col, text_col = st.columns([1, 1])
        with chart_col:
            # Plotly ì°¨íŠ¸
            df_chart = pd.DataFrame({
                "ìƒíƒœ": ["í˜„ì¬ (ê³ ê¸ˆë¦¬)", "ì§€ìƒ AI ì†”ë£¨ì…˜"],
                "ì—°ê°„ ì´ìë¹„ìš© (ë§Œì›)": [4500, 4500 - (facts['saved_interest_year']/10000)]
            })
            fig = px.bar(df_chart, x="ìƒíƒœ", y="ì—°ê°„ ì´ìë¹„ìš© (ë§Œì›)", color="ìƒíƒœ", text_auto=True,
                         color_discrete_sequence=['#ff6b6b', '#1dd1a1'])
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
            
        with text_col:
            st.info("ğŸ’¡ **AI Insight**")
            st.write(ai_text)

        # 3. ìƒì„¸ ë°ì´í„° íƒ­
        st.markdown("---")
        tab1, tab2 = st.tabs(["ğŸ›¡ï¸ ë¬´ê²°ì„± ê²€ì¦ ë°ì´í„° (FactChecker)", "ğŸ’¾ ì›ë³¸ ê³µì ì¥ë¶€ (Opal)"])
        with tab1:
            st.json(facts)
        with tab2:
            st.json(raw)